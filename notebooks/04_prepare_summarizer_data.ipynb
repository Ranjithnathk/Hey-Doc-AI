{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd357dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7a54c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ranji\\My Projects\\Projects\\HeyDocAI\\HeyDocAI\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load from cleaned JSON\n",
    "dataset = load_dataset(\"json\", data_files=\"../data/cleaned_mts_dialogue_summary.json\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8550363",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename_columns({\n",
    "    \"dialogue\": \"input\",\n",
    "    \"section_text\": \"target\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e161adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID': 0,\n",
       " 'section_header': 'GENHX',\n",
       " 'target': 'Symptoms: no fever, no chills, no cough, no congestion, no nausea, no vomiting, no chest pain, no chest pressure.\\nDiagnosis: hypertension, osteoarthritis, osteoporosis, hypothyroidism, allergic rhinitis, kidney stones\\nHistory of Patient: 76-year-old white female, presents to the clinic today originally for hypertension and a med check, followed by Dr. Kumar, issues stable\\nPlan of Action: N/A',\n",
       " 'input': 'Doctor: What brings you back into the clinic today, miss? \\nPatient: I came in for a refill of my blood pressure medicine. \\nDoctor: It looks like Doctor Kumar followed up with you last time regarding your hypertension, osteoarthritis, osteoporosis, hypothyroidism, allergic rhinitis and kidney stones.  Have you noticed any changes or do you have any concerns regarding these issues?  \\nPatient: No. \\nDoctor: Have you had any fever or chills, cough, congestion, nausea, vomiting, chest pain, chest pressure?\\nPatient: No.  \\nDoctor: Great. Also, for our records, how old are you and what race do you identify yourself as?\\nPatient: I am seventy six years old and identify as a white female.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e42bb2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split raw dataset (not tokenized yet!)\n",
    "split_dataset = dataset.train_test_split(test_size=0.1)\n",
    "raw_train = split_dataset[\"train\"]\n",
    "raw_eval = split_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3f89bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tokenizer\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"facebook/bart-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ab9cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the Dataset\n",
    "\n",
    "def tokenize_function(example):\n",
    "    model_inputs = tokenizer(\n",
    "        example[\"input\"],\n",
    "        max_length=512,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True\n",
    "    )\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            example[\"target\"],\n",
    "            max_length=128,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True\n",
    "        )\n",
    "    model_inputs[\"labels\"] = [int(id) for id in labels[\"input_ids\"]]\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48bdb089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/1161 [00:00<?, ? examples/s]c:\\Users\\ranji\\My Projects\\Projects\\HeyDocAI\\HeyDocAI\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3959: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 1161/1161 [00:00<00:00, 2038.21 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 1909.37 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize both splits\n",
    "tokenized_train = raw_train.map(tokenize_function, batched=True)\n",
    "tokenized_eval = raw_eval.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba505fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 1161/1161 [00:00<00:00, 46392.48 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 129/129 [00:00<00:00, 5055.50 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Save Tokenized splits\n",
    "\n",
    "tokenized_train.save_to_disk(\"../data/tokenized_mts_summarizer_train\")\n",
    "tokenized_eval.save_to_disk(\"../data/tokenized_mts_summarizer_eval\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c88c4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
