{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61fb1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eefd7293",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ranji\\My Projects\\Projects\\HeyDocAI\\HeyDocAI\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79a12b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded full dataset with 195696 samples\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"json\", data_files={\"train\": \"../data/cleaned_pubmed_qa.json\"}, split=\"train\")\n",
    "print(\"Loaded full dataset with\", len(dataset), \"samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8086fd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_split = dataset.train_test_split(test_size=0.1)\n",
    "full_train_data = dataset_split[\"train\"]\n",
    "full_eval_data = dataset_split[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b739317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_data = full_train_data.shuffle(seed=42).select(range(1000))\n",
    "small_eval_data = full_eval_data.shuffle(seed=42).select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea724dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'context', 'answer'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5b073da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_checkpoint)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "445a32ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = [\"question: \" + q + \" context: \" + c for q, c in zip(examples[\"question\"], examples[\"context\"])]\n",
    "    targets = examples[\"answer\"]\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=128, truncation=True, padding=\"max_length\")\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1632d0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1000/1000 [00:01<00:00, 748.96 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 669.18 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_train = small_train_data.map(preprocess_function, batched=True)\n",
    "tokenized_eval = small_eval_data.map(preprocess_function, batched=True)\n",
    "print(\"Tokenization complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "757d1653",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    if isinstance(predictions, tuple):\n",
    "        predictions = predictions[0]\n",
    "    pred_ids = np.argmax(predictions, axis=-1)\n",
    "    decoded_preds = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    final_result = {}\n",
    "    for key, value in result.items():\n",
    "        if hasattr(value, 'mid'):\n",
    "            final_result[key] = value.mid.fmeasure * 100\n",
    "        else:\n",
    "            final_result[key] = value * 100\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07195a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../model/final_qa_small\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=1,\n",
    "    logging_dir=\"../model/logs\",\n",
    "    logging_steps=10,\n",
    "    save_steps=1e6,\n",
    "    gradient_accumulation_steps=8,\n",
    "    warmup_steps=10,\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe45259b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ranji\\AppData\\Local\\Temp\\ipykernel_40048\\1631510311.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a38653f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 24:32, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.077000</td>\n",
       "      <td>1.761953</td>\n",
       "      <td>39.446370</td>\n",
       "      <td>12.131592</td>\n",
       "      <td>33.966887</td>\n",
       "      <td>33.923502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.620900</td>\n",
       "      <td>1.656699</td>\n",
       "      <td>40.122698</td>\n",
       "      <td>12.829875</td>\n",
       "      <td>35.266787</td>\n",
       "      <td>35.225219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(\"../model/final_qa_small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65718480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ranji\\My Projects\\Projects\\HeyDocAI\\HeyDocAI\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 00:41]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final ROUGE Metrics on Small Eval Set:\n",
      "eval_loss: 1.64\n",
      "eval_rouge1: 40.15\n",
      "eval_rouge2: 12.97\n",
      "eval_rougeL: 35.42\n",
      "eval_rougeLsum: 35.39\n",
      "eval_runtime: 46.09\n",
      "eval_samples_per_second: 2.17\n",
      "eval_steps_per_second: 2.17\n",
      "epoch: 1.00\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate(eval_dataset=tokenized_eval)\n",
    "print(\"Final ROUGE Metrics on Small Eval Set:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccf03a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145a16fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47661621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc2bdae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a421cfb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d780da2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
